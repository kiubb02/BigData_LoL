{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# This Jupyter Notebook will only cover tasks which have nothing to do with the Story Telling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## API\n",
    "\n",
    "The team tried working with an API but sadly the requests lead to an overhead and for other APIs which would have provided the data needed, subscriptions or licenses had to be bought."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "import json\n",
    "import datetime\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# we need the country list\n",
    "# country list is parted in three seperate lists to keep the rate limit low\n",
    "\n",
    "\n",
    "# keep only in eu since those are also the regulation countries and bigger servers are located there as well\n",
    "europe_country_list = [\"Austria\", \"Belgium\", \"Bulgaria\", \"Croatia\", \"Cyprus\", \"Czechia\", \"Denmark\", \"Estonia\", \"Finland\", \"France\", \"Germany\", \"Greece\", \"Hungary\", \"Iceland\", \"Ireland\", \"Italy\", \"Latvia\", \"Liechtenstein\", \"Lithuania\", \"Luxembourg\", \"Malta\", \"Netherlands\", \"Norway\", \"Poland\", \"Portugal\" , \"Romania\", \"Slovakia\", \"Slovenia\", \"Spain\", \"Sweden\" ]\n",
    "# europe_country_list = [\"Albania\", \"Andorra\", \"Armenia\", \"Austria\", \"Azerbaijan\", \"Belarus\", \"Belgium\", \"Bosnia and Herzegovina\", \"Bulgaria\", \"Croatia\", \"Cyprus\", \"Czech Republic\", \"Denmark\", \"Estonia\", \"Finland\", \"France\", \"Georgia\", \"Germany\", \"Greece\", \"Hungary\", \"Iceland\", \"Ireland\", \"Italy\", \"Kazakhstan\", \"Latvia\", \"Liechtenstein\", \"Lithuania\", \"Luxembourg\", \"Macedonia\", \"Malta\", \"Moldova\", \"Monaco\", \"Montenegro\", \"Netherlands\", \"Norway\", \"Poland\",\"Portugal\",\"Romania\", \"Russia\", \"San Marino\", \"Serbia\", \"Slovakia\", \"Slovenia\", \"Spain\", \"Sweden\", \"Switzerland\", \"Turkey\", \"Ukraine\",\"United Kingdom\", \"Vatican City\"]\n",
    "\n",
    "print(f\"Number of Countries: {len(europe_country_list)}\" )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "url = \"https://covid-193.p.rapidapi.com/history\"\n",
    "\n",
    "headers = {\n",
    "\t\"X-RapidAPI-Key\": \"ba735a5542msh0672a6a248c9225p1ba64djsnfd32c8982360\",\n",
    "\t\"X-RapidAPI-Host\": \"covid-193.p.rapidapi.com\"\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### March Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# collect the results for each country in that specific timeframe\n",
    "# march\n",
    "start_date = datetime.date(2020, 3, 1)\n",
    "end_date = datetime.date(2020, 4, 1)\n",
    "delta = datetime.timedelta(days=1)\n",
    "\n",
    "for country in europe_country_list:\n",
    "    j = []\n",
    "    while start_date <= end_date:\n",
    "        # add a sleep into the while loop to let requests go through better\n",
    "        time.sleep(10)\n",
    "        querystring = {\"country\":f\"{country}\",\"day\":f\"{start_date}\"}\n",
    "        result = requests.request(\"GET\", url, headers=headers, params=querystring)\n",
    "        country_json = result.json()\n",
    "        # put it into the countries json\n",
    "        j.append(country_json)\n",
    "        start_date += delta\n",
    "    # save the json\n",
    "    with open(f\"covid_data/api_data/march/{country}_march.json\", \"w\") as jsonfile:\n",
    "        json.dump(j, jsonfile)\n",
    "    # set start date again\n",
    "    start_date = datetime.date(2020, 3, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### April Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# april\n",
    "start_date = datetime.date(2020, 4, 1)\n",
    "end_date = datetime.date(2020, 5, 1)\n",
    "delta = datetime.timedelta(days=1)\n",
    "\n",
    "for country in europe_country_list:\n",
    "    j = []\n",
    "    while start_date <= end_date:\n",
    "        time.sleep(10)\n",
    "        querystring = {\"country\":f\"{country}\",\"day\":f\"{start_date}\"}\n",
    "        result = requests.request(\"GET\", url, headers=headers, params=querystring)\n",
    "        country_json = result.json()\n",
    "        # put it into the countries json\n",
    "        j.append(country_json)\n",
    "        start_date += delta\n",
    "    # save the json\n",
    "    with open(f\"covid_data/api_data/april/{country}_april.json\", \"w\") as jsonfile:\n",
    "        json.dump(j, jsonfile)\n",
    "    start_date = datetime.date(2020, 4, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Mai Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# mai\n",
    "start_date = datetime.date(2020, 5, 1)\n",
    "end_date = datetime.date(2020, 6, 1)\n",
    "delta = datetime.timedelta(days=1)\n",
    "\n",
    "for country in europe_country_list:\n",
    "    j = []\n",
    "    while start_date <= end_date:\n",
    "        querystring = {\"country\":f\"{country}\",\"day\":f\"{start_date}\"}\n",
    "        result = requests.request(\"GET\", url, headers=headers, params=querystring)\n",
    "        country_json = result.json()\n",
    "        # put it into the countries json\n",
    "        j.append(country_json)\n",
    "        start_date += delta\n",
    "    time.sleep(20)\n",
    "    # save the json\n",
    "    with open(f\"covid_data/api_data/mai/{country}_mai.json\", \"w\") as jsonfile:\n",
    "        json.dump(j, jsonfile)\n",
    "    start_date = datetime.date(2020, 5, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Now that all the data has been collected we should also take a look upon what exactly has been collected and what the data consists of. For each country in our Europe List we collected the *History* of each country. When collecting the history one gets the following data for each date passed:\n",
    "- day\n",
    "- number of results\n",
    "- response : continent, country, population, cases, deaths, tests\n",
    "\n",
    "We are most interested in the cases parameter alongside with which regulations where present during that time.\n",
    "When looking at the cases for each date per country we get the following:\n",
    "- new cases\n",
    "- active cases\n",
    "- critical cases\n",
    "- recovered cases\n",
    "- total cases\n",
    "\n",
    "Let's take a look at one example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "with open('covid_data/api_data/april/Albania_april.json', 'r') as handle:\n",
    "    parsed = json.load(handle)\n",
    "\n",
    "print(json.dumps(parsed, indent=4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "As one can also see: for each date given we get multiple statistical responses since the covid data was obviously updated regularly over the day. We will use the latest given values of the day for our inspections. Furthermore we will only use the number of total cases, since the number of new cases has been stated differently per country ( either they say how much in comparison to before or the total number + the new number ).\n",
    "\n",
    "So to make it easier for us we will create 3 Dataframes, in which each dataframe represents one month with countries, dates and the total cases of that date."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### April DF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# iterate through the folder, parse each file and add the information into the dataframe\n",
    "import os\n",
    "# assign directory\n",
    "directory = 'covid_data/api_data/april'\n",
    "# empty dataframe\n",
    "april_df = pd.DataFrame(columns = [\"Country\", \"DateTime\", \"Total Cases\"])\n",
    "\n",
    "# iterate over files in\n",
    "# that directory\n",
    "for filename in os.listdir(directory):\n",
    "    f = os.path.join(directory, filename)\n",
    "    with open(f, 'r') as handle:\n",
    "        parsed = json.load(handle)\n",
    "        for info in parsed:\n",
    "            # country\n",
    "            country = info['parameters'][\"country\"]\n",
    "            # total numbers\n",
    "            total_cases = info['response'][0][\"cases\"][\"total\"]\n",
    "            # date and time\n",
    "            date_time = info['response'][0][\"time\"]\n",
    "            # add this into the dataframe\n",
    "            april_df = april_df.append({'Country' : country, 'DateTime' : date_time, 'Total Cases' : total_cases}, ignore_index = True)\n",
    "    print(country)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### March DF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# iterate through the folder, parse each file and add the information into the dataframe\n",
    "import os\n",
    "# assign directory\n",
    "directory = 'covid_data/api_data/march'\n",
    "\n",
    "march_df = pd.DataFrame(columns = [\"Country\", \"DateTime\", \"Total Cases\"])\n",
    "\n",
    "# iterate over files in\n",
    "# that directory\n",
    "for filename in os.listdir(directory):\n",
    "    f = os.path.join(directory, filename)\n",
    "    with open(f, 'r') as handle:\n",
    "        parsed = json.load(handle)\n",
    "        for info in parsed:\n",
    "            # country\n",
    "            country = info['parameters'][\"country\"]\n",
    "            # total numbers\n",
    "            total_cases = info['response'][0][\"cases\"][\"total\"]\n",
    "            # date and time\n",
    "            date_time = info['response'][0][\"time\"]\n",
    "            # add this into the dataframe\n",
    "            march_df = march_df.append({'Country' : country, 'DateTime' : date_time, 'Total Cases' : total_cases}, ignore_index = True)\n",
    "    print(country)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Mai DF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# iterate through the folder, parse each file and add the information into the dataframe\n",
    "import os\n",
    "# assign directory\n",
    "directory = 'covid_data/api_data/mai'\n",
    "\n",
    "mai_df = pd.DataFrame(columns = [\"Country\", \"DateTime\", \"Total Cases\"])\n",
    "\n",
    "# iterate over files in\n",
    "# that directory\n",
    "for filename in os.listdir(directory):\n",
    "    f = os.path.join(directory, filename)\n",
    "    with open(f, 'r') as handle:\n",
    "        parsed = json.load(handle)\n",
    "        for info in parsed:\n",
    "            # country\n",
    "            country = info['parameters'][\"country\"]\n",
    "            # total numbers\n",
    "            total_cases = info['response'][0][\"cases\"][\"total\"]\n",
    "            # date and time\n",
    "            date_time = info['response'][0][\"time\"]\n",
    "            # add this into the dataframe\n",
    "            mai_df = mai_df.append({'Country' : country, 'DateTime' : date_time, 'Total Cases' : total_cases}, ignore_index = True)\n",
    "    print(country)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Map Reduce and Spark"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Map Reduce\n",
    "\n",
    "We tried out tiny jobs with Map Reduce on the dataframe of regulations.\n",
    "For that we will focus only on the three specific Months starting with March."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: mrjob in c:\\users\\chiar\\anaconda3\\lib\\site-packages (0.7.4)\n",
      "Requirement already satisfied: PyYAML>=3.10 in c:\\users\\chiar\\anaconda3\\lib\\site-packages (from mrjob) (5.3.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Error parsing requirements for opencv-python: [Errno 2] No such file or directory: 'c:\\\\users\\\\chiar\\\\anaconda3\\\\lib\\\\site-packages\\\\opencv_python-4.5.5.64.dist-info\\\\METADATA'\n",
      "\n",
      "[notice] A new release of pip available: 22.3 -> 22.3.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "pip install mrjob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib as plt\n",
    "import pandas as pd\n",
    "from mrjob.job import MRJob\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How often does each country call upon regulations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing mrjob_job2.py\n"
     ]
    }
   ],
   "source": [
    "%%file mrjob_job2.py\n",
    "from mrjob.job import MRJob\n",
    "from mrjob.step import MRStep\n",
    "\n",
    "class MovieLensData_Analysis(MRJob):\n",
    "    \n",
    "    def mapper(self, _, line):\n",
    "        words = line.split(',')\n",
    "        yield words[0], 1\n",
    "    \n",
    "    def reducer(self, country, values):\n",
    "        yield (country, sum(values))\n",
    "        \n",
    "        \n",
    "if __name__ == '__main__':\n",
    "    MovieLensData_Analysis.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No configs found; falling back on auto-configuration\n",
      "No configs found; falling back on auto-configuration\n",
      "No configs found; falling back on auto-configuration\n",
      "No configs found; falling back on auto-configuration\n",
      "No configs specified for inline runner\n",
      "No configs specified for inline runner\n",
      "No configs specified for inline runner\n",
      "No configs specified for inline runner\n",
      "Creating temp directory C:\\Users\\chiar\\AppData\\Local\\Temp\\mrjob_job2.chiar.20221115.030646.697936\n",
      "Creating temp directory C:\\Users\\chiar\\AppData\\Local\\Temp\\mrjob_job2.chiar.20221115.030646.697936\n",
      "Creating temp directory C:\\Users\\chiar\\AppData\\Local\\Temp\\mrjob_job2.chiar.20221115.030646.697936\n",
      "Creating temp directory C:\\Users\\chiar\\AppData\\Local\\Temp\\mrjob_job2.chiar.20221115.030646.697936\n",
      "Running step 1 of 1...\n",
      "Running step 1 of 1...\n",
      "Running step 1 of 1...\n",
      "Running step 1 of 1...\n",
      "job output is in C:\\Users\\chiar\\AppData\\Local\\Temp\\mrjob_job2.chiar.20221115.030646.697936\\output\n",
      "job output is in C:\\Users\\chiar\\AppData\\Local\\Temp\\mrjob_job2.chiar.20221115.030646.697936\\output\n",
      "job output is in C:\\Users\\chiar\\AppData\\Local\\Temp\\mrjob_job2.chiar.20221115.030646.697936\\output\n",
      "job output is in C:\\Users\\chiar\\AppData\\Local\\Temp\\mrjob_job2.chiar.20221115.030646.697936\\output\n",
      "Streaming final output from C:\\Users\\chiar\\AppData\\Local\\Temp\\mrjob_job2.chiar.20221115.030646.697936\\output...\n",
      "Streaming final output from C:\\Users\\chiar\\AppData\\Local\\Temp\\mrjob_job2.chiar.20221115.030646.697936\\output...\n",
      "Streaming final output from C:\\Users\\chiar\\AppData\\Local\\Temp\\mrjob_job2.chiar.20221115.030646.697936\\output...\n",
      "Streaming final output from C:\\Users\\chiar\\AppData\\Local\\Temp\\mrjob_job2.chiar.20221115.030646.697936\\output...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"\\\"Austria\\\"\"\t83\n",
      "\"\\\"Belgium\\\"\"\t67\n",
      "\"\\\"Bulgaria\\\"\"\t67\n",
      "\"\\\"Country\\\"\"\t1\n",
      "\"\\\"Croatia\\\"\"\t44\n",
      "\"\\\"Cyprus\\\"\"\t70\n",
      "\"\\\"Czechia\\\"\"\t97\n",
      "\"\\\"Denmark\\\"\"\t72\n",
      "\"\\\"Estonia\\\"\"\t79\n",
      "\"\\\"Finland\\\"\"\t38\n",
      "\"\\\"France\\\"\"\t65\n",
      "\"\\\"Germany\\\"\"\t63\n",
      "\"\\\"Greece\\\"\"\t68\n",
      "\"\\\"Hungary\\\"\"\t55\n",
      "\"\\\"Iceland\\\"\"\t72\n",
      "\"\\\"Ireland\\\"\"\t75\n",
      "\"\\\"Italy\\\"\"\t76\n",
      "\"\\\"Latvia\\\"\"\t62\n",
      "\"\\\"Liechtenstein\\\"\"\t57\n",
      "\"\\\"Lithuania\\\"\"\t88\n",
      "\"\\\"Luxembourg\\\"\"\t56\n",
      "\"\\\"Malta\\\"\"\t49\n",
      "\"\\\"Netherlands\\\"\"\t112\n",
      "\"\\\"Norway\\\"\"\t60\n",
      "\"\\\"Poland\\\"\"\t81\n",
      "\"\\\"Portugal\\\"\"\t57\n",
      "\"\\\"Romania\\\"\"\t59\n",
      "\"\\\"Slovakia\\\"\"\t75\n",
      "\"\\\"Slovenia\\\"\"\t80\n",
      "\"\\\"Spain\\\"\"\t61\n",
      "\"\\\"Sweden\\\"\"\t33\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Removing temp directory C:\\Users\\chiar\\AppData\\Local\\Temp\\mrjob_job2.chiar.20221115.030646.697936...\n",
      "Removing temp directory C:\\Users\\chiar\\AppData\\Local\\Temp\\mrjob_job2.chiar.20221115.030646.697936...\n",
      "Removing temp directory C:\\Users\\chiar\\AppData\\Local\\Temp\\mrjob_job2.chiar.20221115.030646.697936...\n",
      "Removing temp directory C:\\Users\\chiar\\AppData\\Local\\Temp\\mrjob_job2.chiar.20221115.030646.697936...\n"
     ]
    }
   ],
   "source": [
    "%run mrjob_job2.py covid_data/country_regulations.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pyspark in c:\\users\\chiar\\anaconda3\\lib\\site-packages (3.3.0)\n",
      "Requirement already satisfied: py4j==0.10.9.5 in c:\\users\\chiar\\anaconda3\\lib\\site-packages (from pyspark) (0.10.9.5)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Error parsing requirements for opencv-python: [Errno 2] No such file or directory: 'c:\\\\users\\\\chiar\\\\anaconda3\\\\lib\\\\site-packages\\\\opencv_python-4.5.5.64.dist-info\\\\METADATA'\n",
      "\n",
      "[notice] A new release of pip available: 22.3 -> 22.3.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "pip install pyspark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import isnan, count, when, col, desc, udf, col, sort_array, asc, avg\n",
    "from pyspark.sql.functions import sum as Fsum\n",
    "from pyspark.sql.window import Window\n",
    "from pyspark.sql.types import IntegerType"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession \\\n",
    "    .builder \\\n",
    "    .appName(\"task\") \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.read.csv(\"covid_data/country_regulations.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- _c0: string (nullable = true)\n",
      " |-- _c1: string (nullable = true)\n",
      " |-- _c2: string (nullable = true)\n",
      " |-- _c3: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get the number of how often all Events were prohibited\n",
    "df.filter(df._c1 == 'BanOnAllEvents') \\\n",
    "    .select('_c0', '_c1') \\\n",
    "    .dropDuplicates() \\\n",
    "    .count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get the number of how often all Mass Gatherings were prohibited\n",
    "df.filter(df._c1 == 'MassGatherAll') \\\n",
    "    .select('_c0', '_c1') \\\n",
    "    .dropDuplicates() \\\n",
    "    .count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the number of how often all Entertainment Venues were prohibited\n",
    "df.filter(df._c1 == 'EntertainmentVenues') \\\n",
    "    .select('_c0', '_c1') \\\n",
    "    .dropDuplicates() \\\n",
    "    .count()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}